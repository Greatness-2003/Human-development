# Don't forget people in the use of big data for development

Joshua Blumenstock states that the promise is to apply algorithms, so they are used to improve international development. The use of algorithms to create maps of crop yields and childhood malnutrition, supply resources to those living in poverty, assist governments in aid distribution in an easier and faster way. These analyses can also be used to boost health interventions during crises such as an epidemic, both on a national and international level.
There are however some drawbacks of this amazing technology, which the author has brought to light. These include unanticipated effects whereby the algorithm brings about some unforeseen results. Some examples of this include, the intended subjects of the algorithm being unable to derive value from it as only a select and privileged have the power to do so. The target group even when able to use the solutions does not benefit from it, but is rather made worse. Such is the case of ‘digital credit’, where most borrowers are unaware of the risks, interest rates they accumulate by taking loans. Eventually, they are worse off than they previously were.  The traditional methods of data collection such as face-to-face interviews have several limitations. These limitations are however documented and understood. The new approaches, on the other hand, have not been sufficiently tested for their faults and limits to be understood, leading to inaccuracy. Also, due to changes in conditions and people's dishonesty, algorithms do not stay accurate for a long period and their values reduce quickly. These algorithms tend to be biased, as they do not favor the set of people they were made for which are the underprivileged individuals. Having a smartphone and social media account is a requirement for a lot of digital credit platforms. This excludes a great majority of the disadvantaged. There is a lack of regulation; The algorithms are mainly owned and run by private companies whose main incentive is profit maximization. And as is often the case, developing countries have nonchalant governments who do not enforce the proper checks and balances on the companies leading to issues of data privacy, unaccountability, etc.  
The author was kind enough to give some solutions to the issues stated above. Validate, new and old sources of data should collaborate. Instead of new methods substituting the old ones, they should be complements, working side-by-side. Customize, algorithms should be customized to suit the specific situation in which they are used, not for general usage. Deepen collaboration; promote cooperation between the private sector, data scientists, governments, etc.  
“Good intent is not enough in data science when dealing with problems that determine people’s experiences” Anna Raymond. In the article, several examples are given where the intention of an algorithm is great but ended failing because of improper application. “Transparency is the underlying issue to many of these problems, so an increase in this on both ends (data-based issues & human-based issues) could lead to better results.” Nira Nair. Transparency is an issue as private companies which run these algorithms are not held accountable for their actions. I would however not agree that it is the underlying issue.
“In lieu of such drastic potential for promoting applications yet demoralizing hindrances, the balancing act can become difficult.” Kayla Seggelke. I believe this
statement to be true. As technology improves, these algorithms become more and more limitless, thereby making it harder to place restrictions and regulations on the makers of the algorithms.
 

